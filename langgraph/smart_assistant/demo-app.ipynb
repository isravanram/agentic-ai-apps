{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os, requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def browse_web(search_term: str):\n",
    "    \"\"\"\n",
    "    search_term: search term to search for information from the web\n",
    "    returns the information retireved for the corresponding search term\n",
    "    \"\"\"\n",
    "    serper = GoogleSerperAPIWrapper()\n",
    "    return serper.run(search_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_url = \"https://api.pushover.net/1/messages.json\"\n",
    "\n",
    "def push(text: str):\n",
    "    \"\"\"Send a push notification to the user\"\"\"\n",
    "    requests.post(pushover_url, data = {\"token\": pushover_token, \"user\": pushover_user, \"message\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_admin_details(_:str):\n",
    "    return {\"name\":\"Ashok\",\"email\":\"ashok@gmail.com\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_browse = Tool(\n",
    "    name=\"browse_internet\",\n",
    "    func=browse_web,\n",
    "    description=\"This tool is used to search the web for a given search term\"\n",
    ")\n",
    "\n",
    "tool_push = Tool(\n",
    "    name=\"push_notification\",\n",
    "    func=push,\n",
    "    description=\"This tool is used to send push notification\"\n",
    ")\n",
    "\n",
    "tool_admin = Tool(\n",
    "    name=\"get_admin_details\",\n",
    "    func=get_admin_details,\n",
    "    description=\"This tool is to get the admin details (Email & personal details of Admin)\"\n",
    ")\n",
    "\n",
    "\n",
    "tools = [tool_browse,tool_push,tool_admin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",temperature=0).bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Ashok', 'email': 'ashok@gmail.com'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_admin.invoke(\"Dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import MessagesState,StateGraph,END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_reasoning_engine(state:MessagesState) -> MessagesState:\n",
    "    \"\"\"\n",
    "    Run the reasoning engine\n",
    "    \"\"\"\n",
    "\n",
    "    system_content = \"\"\"\n",
    "        You are a smart assistant designed to use tools efficiently to answer user queries\n",
    "    \"\"\"\n",
    "    response = llm.invoke([{\"role\":\"system\", \"content\":system_content},*state[\"messages\"]])\n",
    "    return {\"messages\":response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "\n",
    "def tools_condition_manual(state: MessagesState) -> str:\n",
    "    if not state[\"messages\"][-1].tools_call:\n",
    "        return END\n",
    "    return \"reasoning_engine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding memory import \n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "config = {\"configurable\":{\"thread_id\":\"1\"}}\n",
    "\n",
    "flow = StateGraph(MessagesState)\n",
    "\n",
    "ACT = \"reasoning_engine\"\n",
    "TOOL = \"tools\"\n",
    "\n",
    "flow.add_node(ACT,run_reasoning_engine)\n",
    "flow.add_node(TOOL,ToolNode(tools=tools))\n",
    "flow.set_entry_point(\"reasoning_engine\")\n",
    "\n",
    "flow.add_conditional_edges(ACT,tools_condition,TOOL)\n",
    "\n",
    "# flow.add_conditional_edges(\"reasoning_engine\",tools_condition_manual,{\n",
    "#     END:END,\n",
    "#     \"act\":\"reasoning_engine\"\n",
    "# })\n",
    "\n",
    "flow.add_edge(TOOL,ACT)\n",
    "compiled_graph = flow.compile(checkpointer=memory);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+         \n",
      "        | __start__ |         \n",
      "        +-----------+         \n",
      "               *              \n",
      "               *              \n",
      "               *              \n",
      "     +------------------+     \n",
      "     | reasoning_engine |     \n",
      "     +------------------+     \n",
      "          .         *         \n",
      "        ..           **       \n",
      "       .               *      \n",
      "+---------+         +-------+ \n",
      "| __end__ |         | tools | \n",
      "+---------+         +-------+ \n"
     ]
    }
   ],
   "source": [
    "print(compiled_graph.get_graph().draw_ascii())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, history):\n",
    "    \"\"\"\n",
    "    Maps user input to LLM\n",
    "    \"\"\"\n",
    "    res = compiled_graph.invoke({\"messages\": {\"role\":\"user\",\"content\":user_input}},config=config)\n",
    "    return res[\"messages\"][-1].content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked for the current temperature in Tokyo, and then you requested to list that temperature and triple it. I provided the temperature as 81°F and calculated the tripled value as 243°F.\n"
     ]
    }
   ],
   "source": [
    "res = compiled_graph.invoke({\"messages\": [HumanMessage(content=\"What is the temperature in Tokyo? List it and then triple it\")]},config=config)\n",
    "print(res[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current temperature in Dubai is 36°C.\n"
     ]
    }
   ],
   "source": [
    "res = compiled_graph.invoke({\"messages\": [HumanMessage(content=\"What is the temperature in Dubai in Celsius? \")]})\n",
    "print(res[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The admin's name is Ashok, and the email address is ashok@gmail.com.\n"
     ]
    }
   ],
   "source": [
    "res = compiled_graph.invoke({\"messages\": [HumanMessage(content=\"Give me info about the admin? \")]})\n",
    "print(res[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langraphenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
